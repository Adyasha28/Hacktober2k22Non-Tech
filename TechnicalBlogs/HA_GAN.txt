Generative adversarial networks have shown success in generating realistic-looking natural images. Image reconstruction, image-to-image translation and model- explanation are some areas in medical science where GAN model can be proved useful. Here we are proposing an efficient method for generating and extracting features from high-resolution volumetric images. The training procedure of GANs can be correlated with to a min-max game between two players that is a generator and a discriminator. Generator, generates realistic-looking image based on different random inputs, the discriminator aims to defeat the generator by recognizing and pointing the difference between real and the generated images. 

 

As some of the previous works has proposed to use 3D GAN for diverse medical applications but the generated images are limited to the small size of 128 × 128 × 128 or below, due to insufficient memory during training. In this paper, we are trying introduce a Hierarchical Amortized GAN (HA-GAN) to bridge the gap between lower sizer and high size images. Our model adopts different configurations between training and inference phases to obtain the high-resolution image with memory efficiency concept. In the training phase, we simultaneously generate a low-resolution image and a randomly selected sub-volume of the high-resolution image. Generating sub-volumes amortizes the memory cost of the high-resolution image and keeping the local details of the 3D image intact. The low-resolution image ensures anatomical consistency and the global structure of the generated images. Here we are training the model in an end-to-end process while retaining memory efficiency concept, so the memory bottleneck, is needed only during training. Hence, sub-volume selection is can be avoided and generation of the entire high-resolution can be done easily in inference phase.
An Encoder in a similar fashion can be implemented to extract features from a given image and prevents the model from mode collapse.

